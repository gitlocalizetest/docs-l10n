{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wFPyjGqMQ82Q"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "aNZ7aEDyQIYU"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMOmzhPEQh7b"
      },
      "source": [
        "# Нормировки\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/addons/tutorials/layers_normalizations\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> Посмотреть на TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/layers_normalizations.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"> Запустить в Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/addons/blob/master/docs/tutorials/layers_normalizations.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Посмотреть источник на GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/addons/docs/tutorials/layers_normalizations.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\"> Скачать блокнот</a></td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cthm5dovQMJl"
      },
      "source": [
        "## обзор\n",
        "\n",
        "Этот блокнот дает краткое введение в [уровни нормализации](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/normalizations.py) TensorFlow. В настоящее время поддерживаются следующие слои:\n",
        "\n",
        "- **Групповая нормализация** (аддоны TensorFlow)\n",
        "- **Нормализация экземпляров** (аддоны TensorFlow)\n",
        "- **Нормализация слоя** (TensorFlow Core)\n",
        "\n",
        "Основная идея этих слоев - нормализовать вывод слоя активации, чтобы улучшить конвергенцию во время обучения. В отличие от [пакетной нормализации](https://keras.io/layers/normalization/) эти нормализации не работают с пакетами, вместо этого они нормализуют активации одного образца, что делает их пригодными и для повторяющихся новых сетей.\n",
        "\n",
        "Обычно нормализация выполняется путем вычисления среднего значения и стандартного отклонения подгруппы во входном тензоре. К этому также можно применить масштаб и коэффициент смещения.\n",
        "\n",
        "$ y_ {i} = \\ frac {\\ gamma (x_ {i} - \\ mu)} {\\ sigma} + \\ beta $\n",
        "\n",
        "$ y $: вывод\n",
        "\n",
        "$ x $: вход\n",
        "\n",
        "$ \\ gamma $: коэффициент масштабирования\n",
        "\n",
        "$ \\ mu $: среднее\n",
        "\n",
        "$ \\ sigma $: стандартное отклонение\n",
        "\n",
        "$ \\ beta $: коэффициент смещения\n",
        "\n",
        "Следующее изображение демонстрирует разницу между этими методами. Каждый субплот показывает входной тензор с N в качестве оси пакета, C в качестве оси канала и (H, W) в качестве пространственных осей (например, высота и ширина изображения). Пиксели синего цвета нормализуются с помощью того же среднего значения и дисперсии, которые вычисляются путем суммирования значений этих пикселей.\n",
        "\n",
        "![](https://github.com/shaohua0116/Group-Normalization-Tensorflow/raw/master/figure/gn.png)\n",
        "\n",
        "Источник: (https://arxiv.org/pdf/1803.08494.pdf)\n",
        "\n",
        "Веса гамма и бета обучаемы на всех уровнях нормализации, чтобы компенсировать возможную потерю репрезентативной способности. Вы можете активировать эти факторы, установив `center` или флаг `scale` на `True` . Конечно, вы можете использовать `initializers` , `constraints` и `regularizer` для `beta` и `gamma` чтобы настроить эти значения в процессе обучения. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I2XlcXf5WBHb"
      },
      "source": [
        "## Настроить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kTlbneoEUKrD"
      },
      "source": [
        "### Установите Tensorflow 2.0 и Tensorflow-Addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7aGgPZG_WBHg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u82Gz_gOUPDZ"
      },
      "source": [
        "### Подготовка набора данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3wso9oidUZZQ"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UTQH56j89POZ"
      },
      "source": [
        "## Учебник по нормализации группы\n",
        "\n",
        "### Введение\n",
        "\n",
        "Групповая нормализация (GN) разделяет каналы ваших входов на более мелкие подгруппы и нормализует эти значения на основе их среднего значения и дисперсии. Поскольку GN работает на одном примере, этот метод не зависит от размера пакета.\n",
        "\n",
        "GN экспериментально забил закрытый для пакетной нормализации в задачах классификации изображений. Может быть выгодно использовать GN вместо нормализации партии, если ваш общий размер пакета batch_size низкий, что может привести к плохой производительности нормализации партии\n",
        "\n",
        "### Пример Разделение 10 каналов после слоя Conv2D на 5 подгрупп в стандартной настройке «последний канал»:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aIGjLwYWAm0v"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  # Reshape into \"channels last\" setup.\n",
        "  tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
        "  tf.keras.layers.Conv2D(filters=10, kernel_size=(3,3),data_format=\"channels_last\"),\n",
        "  # Groupnorm Layer\n",
        "  tfa.layers.GroupNormalization(groups=5, axis=3),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMwUfJUib3ka"
      },
      "source": [
        "## Учебник по нормализации экземпляров\n",
        "\n",
        "### Введение\n",
        "\n",
        "Нормализация экземпляра - это особый случай нормализации группы, когда размер группы равен размеру канала (или размеру оси).\n",
        "\n",
        "Экспериментальные результаты показывают, что нормализация экземпляра хорошо работает при передаче стиля при замене пакетной нормализации. Недавно нормализация экземпляров также использовалась в качестве замены для нормализации партии в GAN.\n",
        "\n",
        "### пример\n",
        "\n",
        "Применение InstanceNormalization после слоя Conv2D и использование унифицированного масштабированного инициализированного масштаба и коэффициента смещения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6sLVv-C8f6Kf"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  # Reshape into \"channels last\" setup.\n",
        "  tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
        "  tf.keras.layers.Conv2D(filters=10, kernel_size=(3,3),data_format=\"channels_last\"),\n",
        "  # LayerNorm Layer\n",
        "  tfa.layers.InstanceNormalization(axis=3, \n",
        "                                   center=True, \n",
        "                                   scale=True,\n",
        "                                   beta_initializer=\"random_uniform\",\n",
        "                                   gamma_initializer=\"random_uniform\"),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qYdnEocRUCll"
      },
      "source": [
        "## Учебник по нормализации слоя\n",
        "\n",
        "### Введение\n",
        "\n",
        "Нормализация уровня - это особый случай нормализации группы, когда размер группы равен 1. Среднее значение и стандартное отклонение рассчитывается по всем активациям одной выборки.\n",
        "\n",
        "Экспериментальные результаты показывают, что нормализация слоев хорошо подходит для рекуррентных нейронных сетей, поскольку она работает в пакетном режиме независимо.\n",
        "\n",
        "### пример\n",
        "\n",
        "Применение нормализации слоя после слоя Conv2D и использование масштаба и коэффициента смещения. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fh-Pp_e5UB54"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  # Reshape into \"channels last\" setup.\n",
        "  tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
        "  tf.keras.layers.Conv2D(filters=10, kernel_size=(3,3),data_format=\"channels_last\"),\n",
        "  # LayerNorm Layer\n",
        "  tf.keras.layers.LayerNormalization(axis=1 , center=True , scale=True),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "shvGfnB0WpQQ"
      },
      "source": [
        "## Литература\n",
        "\n",
        "[Норма слоя](https://arxiv.org/pdf/1607.06450.pdf)\n",
        "\n",
        "[Норма экземпляра](https://arxiv.org/pdf/1607.08022.pdf)\n",
        "\n",
        "[Групповая норма](https://arxiv.org/pdf/1803.08494.pdf)\n",
        "\n",
        "[Полный обзор нормализации](http://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "layers_normalizations.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
