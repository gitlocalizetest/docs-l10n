# Оптимизация производительности TensorFlow с помощью профилировщика

[ТОС]

Используйте инструменты, доступные в Profiler, чтобы отслеживать производительность ваших моделей TensorFlow. Посмотрите, как ваша модель работает на хосте (CPU), устройстве (GPU) или на комбинации хоста и устройства.

Профилирование помогает понять потребление аппаратных ресурсов (время и память) различных операций (операций) TensorFlow в вашей модели, устранить узкие места в производительности и, в конечном итоге, ускорить выполнение модели.

В этом руководстве вы узнаете, как установить Profiler, различные доступные инструменты, различные способы сбора данных о производительности, а также некоторые рекомендуемые рекомендации по оптимизации производительности модели.

If you want to profile your model performance on Cloud TPUs, refer to the [Cloud TPU guide](https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_profile).

## Установите необходимые профилировщик и графический процессор

Установите Profiler, загрузив и запустив скрипт [`install_and_run.py`](https://raw.githubusercontent.com/tensorflow/profiler/master/install_and_run.py) из [репозитория GitHub](https://github.com/tensorflow/profiler) .

Для профилирования на GPU необходимо:

1. [Установите CUDA® Toolkit 10.1](https://www.tensorflow.org/install/gpu#linux_setup) или новее. CUDA® Toolkit 10.1 поддерживает только профилирование одного графического процессора. Для профилирования нескольких графических процессоров см. [Профилирование нескольких графических процессоров](#profile_multiple_gpus) . Убедитесь, что версия устанавливаемого вами драйвера CUDA® составляет не менее 440,33 для Linux или 441,22 для Windows.

2. Убедитесь, что CUPTI существует на пути:

    ```shell
    /sbin/ldconfig -N -v $(sed 's/:/ /g' <<< $LD_LIBRARY_PATH) | \
    grep libcupti
    ```

If you don't have CUPTI on the path, prepend its installation directory to the `$LD_LIBRARY_PATH` environment variable by running:

```shell
export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH
```

Выполните команду `ldconfig` выше, чтобы убедиться, что библиотека CUPTI найдена.

### Профилировать несколько графических процессоров {: id = 'profile_multiple_gpus'}

TensorFlow официально еще не поддерживает профилирование нескольких графических процессоров. Вы можете установить CUDA® Toolkit 10.2 или новее для профилирования нескольких графических процессоров. Поскольку TensorFlow поддерживает версии CUDA® Toolkit только до 10.1, создайте символические ссылки на `libcudart.so.10.1` и `libcupti.so.10.1` .

```shell
sudo ln -s /usr/local/cuda/lib64/libcudart.so.10.2 /usr/local/cuda/lib64/libcudart.so.10.1
sudo ln -s /usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.2 /usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.1
```

Чтобы профилировать конфигурации GPU с несколькими рабочими, профилируйте отдельных рабочих независимо.

## Инструменты профилировщика

Доступ к профилировщику можно получить на вкладке « **Профиль** » в TensorBoard, которая появляется только после того, как вы собрали некоторые данные модели. Профилировщик имеет набор инструментов для анализа производительности:

- Обзорная страница
- Анализатор входного конвейера
- Статистика TensorFlow
- Средство просмотра трассировки
- Статистика ядра GPU

### Обзорная страница

Страница обзора предоставляет представление верхнего уровня о том, как ваша модель работала во время выполнения профиля. На этой странице отображается сводная обзорная страница для вашего хоста и всех устройств, а также некоторые рекомендации по повышению эффективности обучения модели. Вы также можете выбрать отдельные хосты в раскрывающемся списке Хост.

Страница обзора отображает данные следующим образом:

![образ](./images/tf_profiler/overview_page.png)

- **Сводка производительности -** отображает сводную информацию о производительности вашей модели. Сводная информация о производительности состоит из двух частей:

    1. Разбивка по времени шага - разбивает среднее время шага на несколько категорий, по которым тратится время:

        - Компиляция - время, потраченное на компиляцию ядер
        - Ввод - время, затраченное на чтение входных данных
        - Вывод - время, затраченное на чтение выходных данных
        - Запуск ядра - время, затраченное хостом на запуск ядра
        - Время вычисления хоста
        - Время связи между устройствами
        - Время вычислений на устройстве
        - Все остальные, включая накладные расходы на Python

    2. Точность вычислений устройства - сообщает процент времени вычисления устройства, которое использует 16- и 32-разрядные вычисления

- **График шага -** отображает график времени шага устройства (в миллисекундах) для всех выбранных шагов. Каждый шаг разбит на несколько категорий (с разными цветами) того, где тратится время. Красная область соответствует части времени шага, когда устройства простаивали в ожидании ввода данных от хоста. Зеленая область показывает, сколько времени устройство фактически работало

- **Top 10 TensorFlow operations on device -** Displays the on-device ops that ran the longest.

    В каждой строке отображается собственное время оператора (в процентах от времени, затраченного всеми операциями), совокупное время, категория и имя.

- **Среда выполнения -** отображает сводную информацию о среде выполнения модели, включая:

    - Количество используемых хостов
    - Тип устройства (GPU / TPU)
    - Количество ядер устройства

- **Рекомендация для следующих шагов -** сообщает, когда модель привязана к входу, и рекомендует инструменты, которые можно использовать для поиска и устранения узких мест в производительности модели.

### Анализатор входного конвейера

Когда программа TensorFlow читает данные из файла, она начинается с вершины графа TensorFlow конвейерным способом. Процесс чтения разделен на несколько последовательных этапов обработки данных, где выход одного этапа является входом для следующего. Эта система чтения данных называется *входным конвейером* .

Типичный конвейер для чтения записей из файлов имеет следующие этапы:

1. Чтение файлов
2. Предварительная обработка файла (необязательно)
3. Передача файлов с хоста на устройство

Неэффективный входной конвейер может сильно замедлить ваше приложение. Приложение считается **входным привязанным,** когда оно проводит значительную часть времени во входном конвейере. Используйте выводы, полученные из анализатора входного конвейера, чтобы понять, где входной конвейер неэффективен.

Анализатор входного конвейера немедленно сообщает, привязана ли ваша программа к входу, и проводит анализ на стороне устройства и хоста для устранения узких мест производительности на любом этапе входного конвейера.

См. Руководство по производительности входного конвейера, в котором приведены рекомендуемые рекомендации по оптимизации ваших конвейеров ввода данных.

#### Панель ввода конвейера

To open the input pipeline analyzer, select **Profile**, then select **input_pipeline_analyzer** from the **Tools** dropdown.

![образ](./images/tf_profiler/input_pipeline_analyzer.png)

Панель инструментов содержит три раздела:

1. **Сводка -** Суммирует весь входной конвейер с информацией о том, ограничено ли ваше приложение входными данными и, если да, то насколько
2. **Анализ на стороне устройства -** отображает подробные результаты анализа на стороне устройства, включая время выполнения шага устройства и диапазон времени, потраченного устройством на ожидание ввода данных по ядрам на каждом шаге.
3. Анализ на стороне хоста **-** показывает подробный анализ на стороне хоста, включая разбивку времени обработки ввода на хосте

#### Сводка входного конвейера

Сводка сообщает, если ваша программа связана с вводом, представляя процент времени, потраченного устройством на ожидание ввода от хоста. Если вы используете стандартный входной конвейер, который был инструментирован, инструмент сообщает, на что потрачена большая часть времени обработки ввода.

#### Анализ на стороне устройства

Анализ на стороне устройства дает представление о времени, проведенном на устройстве по сравнению с хостом, и о том, сколько времени было потрачено устройством на ожидание входных данных с хоста.

1. **Время шага в зависимости от номера шага -** отображает график времени шага устройства (в миллисекундах) для всех выбранных шагов. Каждый шаг разбит на несколько категорий (с разными цветами) того, где тратится время. Красная область соответствует части времени шага, когда устройства простаивали в ожидании ввода данных от хоста. Зеленая область показывает, сколько времени устройство фактически работало
2. **Статистика времени шага -** сообщает среднее, стандартное отклонение и диапазон ([минимум, максимум]) времени шага устройства.

#### Анализ на стороне хоста

The host-side analysis reports a breakdown of the input processing time (the time spent on `tf.data` API ops) on the host into several categories:

- **Чтение данных из файлов по требованию.** Время, затрачиваемое на чтение данных из файлов без кэширования, предварительной выборки и чередования.
- **Предварительное чтение данных из файлов -** время, затраченное на чтение файлов, включая кэширование, предварительную выборку и чередование
- **Предварительная обработка данных -** время, затрачиваемое на операции предварительной обработки, такие как распаковка изображений
- **Постановка в очередь данных для передачи на устройство -** время, потраченное на помещение данных в очередь на подачу перед передачей данных на устройство

Разверните **Input Op Statistics** для просмотра статистики по отдельным операциям ввода и их категориям с разбивкой по времени выполнения.

![образ](./images/tf_profiler/input_op_stats.png)

Таблица исходных данных появляется с каждой записью, содержащей следующую информацию:

1. **Input Op -** показывает название операции TensorFlow для операции ввода
2. Количество **-** показывает общее количество экземпляров выполнения операции за период профилирования
3. **Общее время (в мс) -** показывает совокупную сумму времени, потраченного на каждый из этих экземпляров
4. **Общее время% -** показывает общее время, потраченное на операцию как часть общего времени, потраченного на обработку ввода
5. **Total Self Time (в мс) -** показывает совокупную сумму собственного времени, потраченного на каждый из этих экземпляров. Собственное время здесь измеряет время, проведенное внутри тела функции, исключая время, потраченное на функцию, которую она вызывает.
6. **Всего собственного времени%** . Показывает общее собственное время как часть общего времени, затраченного на обработку ввода
7. **Категория** . Показывает категорию обработки ввода ввода

### Статистика TensorFlow

Инструмент TensorFlow Stats отображает производительность каждой операции TensorFlow, которая выполняется на хосте или устройстве во время сеанса профилирования.

![образ](./images/tf_profiler/tf_stats.png)

Инструмент отображает информацию о производительности в двух областях:

- Верхняя панель отображает до четырех круговых диаграмм:

    1. Распределение времени выполнения каждого опа на хосте
    2. Распределение времени выполнения каждого типа операций на хосте
    3. Распределение времени выполнения каждого опа на устройстве
    4. Распределение времени выполнения каждого типа операций на устройстве

- На нижней панели показана таблица, в которой представлены данные об операциях TensorFlow с одной строкой для каждой операции и одним столбцом для каждого типа данных (сортируйте столбцы, щелкая заголовок столбца). Нажмите кнопку «Экспортировать как CSV» в правой части верхней панели, чтобы экспортировать данные из этой таблицы в виде файла CSV.

    Обратите внимание, что:

    - Если какие-либо операции имеют дочерние операции:

        - Общее «накопленное» время операции включает время, проведенное внутри дочерней операции.
        - Общее «само» время операции не включает время, проведенное внутри детской операции.

    - Если операция выполняется на хосте:

        - Процент общего времени автономной работы устройства, вызванного операцией, будет равен 0
        - Кумулятивный процент от общего времени автономной работы устройства, включая эту операцию, будет равен 0

    - Если операция выполняется на устройстве:

        - Процент общего времени на хосте, понесенный этой операцией, будет 0
        - Совокупный процент общего времени на хосте и включая эту операцию будет 0

Вы можете включить или исключить время простоя в круговых диаграммах и таблице.

### Средство просмотра трассировки

Средство просмотра трассировки отображает временную шкалу, которая показывает:

- Продолжительность операций, которые были выполнены вашей моделью TensorFlow
- Какая часть системы (хост или устройство) выполнила оп. Как правило, хост выполняет операции ввода, предварительно обрабатывает данные обучения и передает их на устройство, в то время как устройство выполняет обучение фактической модели.

Средство просмотра трассировки позволяет выявлять проблемы с производительностью в вашей модели, а затем предпринимать шаги для их устранения. Например, на высоком уровне вы можете определить, занимает ли вводное или модельное обучение большую часть времени. Развернув детали, вы можете определить, какие операции выполняются дольше всего.

Обратите внимание, что средство просмотра трассировки ограничено 1 миллионом событий на устройство.

#### Интерфейс просмотра трассировки

Когда вы открываете трассировщик, он отображает ваш последний запуск:

![образ](./images/tf_profiler/trace_viewer.png)

Этот экран содержит следующие основные элементы:

1. **Timeline pane -** Shows ops that the device and the host executed over time
2. **Details pane -** Shows additional information for ops selected in the Timeline pane

Панель «Таймлайн» содержит следующие элементы:

1. **Верхняя панель -** содержит различные вспомогательные элементы управления
2. **Ось времени -** показывает время относительно начала трассы.
3. **Section and track labels -** Each section contains multiple tracks and has a triangle on the left that you can click to expand and collapse the section. There is one section for every processing element in the system
4. **Селектор инструментов -** содержит различные инструменты для взаимодействия со средством просмотра трассировки, такие как Zoom, Pan, Select и Timing. Используйте инструмент Timing, чтобы отметить временной интервал.
5. **События -** они показывают время, в течение которого была выполнена операция, или продолжительность мета-событий, таких как этапы обучения

##### Разделы и дорожки

Средство просмотра трассировки содержит следующие разделы:

- **Один раздел для каждого узла устройства** , помеченный номером чипа устройства и узла устройства в чипе (например, `/device:GPU:0 (pid 0)` ). Каждый раздел узла устройства содержит следующие дорожки:
    - **Шаг -** показывает продолжительность шагов обучения, которые выполнялись на устройстве
    - **TensorFlow Ops -** . Показывает операции, выполненные на устройстве
    - **XLA Ops -** показывает операции [XLA](https://www.tensorflow.org/xla/) (ops), которые выполнялись на устройстве, если XLA является используемым компилятором (каждая операция TensorFlow переводится в одну или несколько операций XLA. Компилятор XLA преобразует операции XLA в код, который выполняется на устройстве).
- **Один раздел для потоков, работающих на ЦП хост-машины,** помечен как **«Потоки хоста»** . Раздел содержит одну дорожку для каждого потока процессора. Примечание. Вы можете игнорировать информацию, отображаемую рядом с метками разделов.

##### События

События на временной шкале отображаются разными цветами; Сами цвета не имеют конкретного значения.

### Статистика ядра GPU

Этот инструмент показывает статистику производительности и исходные операции для каждого ядра, ускоренного с помощью графического процессора.

![образ](./images/tf_profiler/gpu_kernel_stats.png)

Инструмент отображает информацию в двух панелях:

- Верхняя панель отображает круговую диаграмму, которая показывает ядра CUDA, которые имеют наибольшее общее время, прошедшее

- В нижней панели отображается таблица со следующими данными для каждой уникальной пары kernel-op:

    - Ранг в порядке убывания общей продолжительности GPU, сгруппированный по паре ядро-опера
    - Название запущенного ядра
    - Количество регистров графического процессора, используемых ядром
    - Общий размер разделяемой (статической + динамически разделяемой) памяти, используемой в байтах
    - Размер блока, выраженный в `blockDim.x, blockDim.y, blockDim.z`
    - Размеры сетки выражаются в виде `gridDim.x, gridDim.y, gridDim.z`
    - Имеет ли право право использовать TensorCores
    - Содержит ли ядро инструкции TensorCore
    - Название оп, который запустил это ядро
    - Количество вхождений этой пары ядро-опера
    - Общее время, затраченное GPU в микросекундах
    - Среднее время работы GPU в микросекундах
    - Минимальное время, затраченное GPU в микросекундах
    - Максимальное время, затраченное GPU в микросекундах

## Сбор данных о производительности

TensorFlow Profiler собирает действия хоста и трассировки GPU вашей модели TensorFlow. Вы можете настроить Profiler для сбора данных о производительности либо в программном режиме, либо в режиме выборки.

- Programmatic mode using the TensorBoard Keras Callback (`tf.keras.callbacks.TensorBoard`)

    ```python
    # Profile from batches 10 to 15
    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,
                                                 profile_batch='10, 15')

    # Train the model and use the TensorBoard Keras callback to collect
    # performance profiling data
    model.fit(train_data,
              steps_per_epoch=20,
              epochs=5,
              callbacks=[tb_callback])
    ```

- Программный режим с использованием API функции `tf.profiler`

    ```python
    tf.profiler.experimental.start('logdir')
    # Train the model here
    tf.profiler.experimental.stop()
    ```

- Программный режим с использованием контекстного менеджера

    ```python
    with tf.profiler.experimental.Profile('logdir'):
        # Train the model here
        pass
    ```

Примечание: слишком долгое выполнение Profiler может привести к нехватке памяти. Рекомендуется профилировать не более 10 шагов одновременно. Избегайте профилирования первых нескольких пакетов, чтобы избежать неточностей из-за издержек инициализации.

- Режим выборки. Выполните профилирование по требованию с помощью `tf.profiler.experimental.server.start()` чтобы запустить сервер gRPC при запуске модели TensorFlow. После запуска сервера gRPC и запуска вашей модели вы можете захватить профиль с помощью кнопки **Capture Profile** в плагине профиля TensorBoard. Используйте сценарий в разделе «Установка профилировщика» выше, чтобы запустить экземпляр TensorBoard, если он еще не запущен.

    Например,

    ```python
    # Start a gRPC server at port 6009
    tf.profiler.experimental.server.start(6009)
    # ... TensorFlow program ...
    ```

![образ](./images/tf_profiler/capture_profile.png)

Вы можете указать URL-адрес службы профилей или имя TPU, продолжительность профилирования и сколько раз вы хотите, чтобы Profiler повторил попытку захвата профилей, если сначала это не удалось.

## Лучшие практики для оптимальной производительности модели

Используйте следующие рекомендации, применимые к вашим моделям TensorFlow, для достижения оптимальной производительности.

В общем, выполните все преобразования на устройстве и убедитесь, что вы используете последнюю совместимую версию библиотек, таких как cuDNN и Intel MKL, для вашей платформы.

### Оптимизировать конвейер входных данных

Эффективный конвейер ввода данных может значительно повысить скорость выполнения вашей модели за счет сокращения времени простоя устройства. Рассмотрите возможность включения следующих рекомендаций, как описано [здесь,](https://www.tensorflow.org/guide/data_performance) чтобы сделать ваш конвейер ввода данных более эффективным:

- Предварительная выборка данных
- Распараллелить извлечение данных
- Распараллелить преобразование данных
- Кэшировать данные в памяти
- Векторизация пользовательских функций
- Уменьшите использование памяти при применении преобразований

Кроме того, попробуйте запустить модель с синтетическими данными, чтобы проверить, является ли входной конвейер узким местом в производительности.

### Улучшить производительность устройства

- Увеличение размера мини-пакета обучения (количество обучающих выборок, используемых на устройство в одной итерации цикла обучения)
- Используйте TF Stats, чтобы узнать, насколько эффективно выполняются операции на устройстве.
- Используйте `tf.function` для выполнения вычислений и при необходимости включите флаг `experimental_compile`
- Минимизируйте операции хоста Python между шагами и уменьшите количество обратных вызовов. Рассчитать метрики каждые несколько шагов, а не на каждом этапе
- Держите вычислительные устройства устройства занятыми
- Отправка данных на несколько устройств параллельно
- Оптимизируйте расположение данных, чтобы сначала отдавать предпочтение каналам (например, NCHW, а не NHWC). Некоторые графические процессоры, такие как NVIDIA® V100, работают лучше с разметкой данных NHWC.
- Consider using 16-bit numerical representations such as `fp16`, the half-precision floating point format specified by IEEE or the Brain floating-point [bfloat16](https://cloud.google.com/tpu/docs/bfloat16) format
- Рассмотрите возможность использования [API со смешанной точностью Keras](https://www.tensorflow.org/guide/keras/mixed_precision)
- При обучении на графических процессорах используйте TensorCore. Ядра графического процессора используют TensorCore, когда точность равна fp16, а размеры ввода / вывода делятся на 8 или 16 (для int8)

## Дополнительные ресурсы

- See the end-to-end [TensorBoard profiler tutorial](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) to implement the advice in this guide.
- Смотрите [выступление по профилированию производительности в TF 2](https://www.youtube.com/watch?v=pXHAQIhhMhI) на TensorFlow Dev Summit 2020.
