{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Лучшая производительность с API tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/data_performance\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> Посмотреть на TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"> Запустить в Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Посмотреть источник на GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/data_performance.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\"> Скачать блокнот</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## TRANSLATION WITH TYPO\n",
        "\n",
        "GPUs and TPUs can radically reduce the time required to execute a single training step. Achieving peak performance requires an efficient input pipeline that delivers data for the next step before the current step has finished. The `tf.data` API helps to build flexible and efficient input pipelines. This document demonstrates how to use the `tf.data` API to build highly performant TensorFlow input pipelines.\n",
        "\n",
        "Before you continue, read the \"[Build TensorFlow input pipelines](./data.ipynb)\" guide, to learn how to use the `tf.data` API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## Ресурсы\n",
        "\n",
        "- [Построить входные конвейеры TensorFlow](./data.ipynb)\n",
        "- API `tf.data.Dataset`\n",
        "- [Проанализируйте производительность `tf.data` с помощью TF Profiler](./data_performance_analysis.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Настроить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QthTHCKF-jKD"
      },
      "source": [
        "В этом руководстве вы будете перебирать набор данных и измерять производительность. Создание воспроизводимых эталонов производительности может быть затруднено, на него влияют различные факторы:\n",
        "\n",
        "- текущая загрузка процессора,\n",
        "- сетевой трафик,\n",
        "- сложные механизмы, такие как кэш и т. д.\n",
        "\n",
        "Следовательно, чтобы обеспечить воспроизводимый тест, создайте искусственный пример."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3bU5gsSI-jKF"
      },
      "source": [
        "### Набор данных\n",
        "\n",
        "Определите класс, унаследованный от `tf.data.Dataset` именем `ArtificialDataset` . Этот набор данных:\n",
        "\n",
        "- генерирует образцы `num_samples` (по умолчанию 3)\n",
        "- спит какое-то время перед первым элементом, имитирующим открытие файла\n",
        "- спит в течение некоторого времени перед созданием каждого элемента для имитации чтения данных из файла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zUQv4kCd-jKH"
      },
      "outputs": [],
      "source": [
        "class ArtificialDataset(tf.data.Dataset):\n",
        "    def _generator(num_samples):\n",
        "        # Opening the file\n",
        "        time.sleep(0.03)\n",
        "        \n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            time.sleep(0.015)\n",
        "            \n",
        "            yield (sample_idx,)\n",
        "    \n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=tf.dtypes.int64,\n",
        "            output_shapes=(1,),\n",
        "            args=(num_samples,)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O9y1WjNv-jKL"
      },
      "source": [
        "Этот набор данных аналогичен `tf.data.Dataset.range` , добавляя фиксированную задержку в начале и между каждой выборкой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FGK1Y4jn-jKM"
      },
      "source": [
        "### Тренировочная петля\n",
        "\n",
        "Напишите фиктивный обучающий цикл, который измеряет, сколько времени требуется для итерации по набору данных. Время тренировки моделируется."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MIaM3u00-jKP"
      },
      "outputs": [],
      "source": [
        "def benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        for sample in dataset:\n",
        "            # Performing a training step\n",
        "            time.sleep(0.01)\n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KK58SuXS-jKT"
      },
      "source": [
        "## Оптимизировать производительность\n",
        "\n",
        "Чтобы продемонстрировать, как можно оптимизировать производительность, вы улучшите производительность `ArtificialDataset` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xi8t26y7-jKV"
      },
      "source": [
        "### Наивный подход\n",
        "\n",
        "Начните с простого конвейера, не используя трюков, итерируя по набору данных как есть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_gP7J1y4-jKY"
      },
      "outputs": [],
      "source": [
        "benchmark(ArtificialDataset())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lxeat5dH-jKf"
      },
      "source": [
        "Под капотом вот как тратится ваше время исполнения:\n",
        "\n",
        "![наивный](https://www.tensorflow.org/guide/images/data_performance/naive.svg)\n",
        "\n",
        "Вы можете видеть, что выполнение этапа обучения включает в себя:\n",
        "\n",
        "- открытие файла, если он еще не открыт,\n",
        "- извлечение записи данных из файла,\n",
        "- используя данные для обучения.\n",
        "\n",
        "Однако в наивной синхронной реализации, как здесь, пока ваш конвейер извлекает данные, ваша модель бездействует. И наоборот, пока ваша модель тренируется, входной конвейер бездействует. Таким образом, время шага обучения - это сумма времени всех, времени открытия, чтения и обучения.\n",
        "\n",
        "Следующие разделы основаны на этом входном конвейере, иллюстрируя лучшие практики для разработки производительных входных конвейеров TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mfukBGNz-jKh"
      },
      "source": [
        "### Предзагрузка\n",
        "\n",
        "Предварительная выборка перекрывает предварительную обработку и выполнение модели этапа обучения. Пока модель выполняет этап обучения `s` , входной конвейер считывает данные для этапа `s+1` . Это сокращает время шага до максимума (в отличие от суммы) обучения и время, необходимое для извлечения данных.\n",
        "\n",
        "The `tf.data` API provides the `tf.data.Dataset.prefetch` transformation. It can be used to decouple the time when data is produced from the time when data is consumed. In particular, the transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. You could either manually tune this value, or set it to `tf.data.experimental.AUTOTUNE` which will prompt the `tf.data` runtime to tune the value dynamically at runtime.\n",
        "\n",
        "Обратите внимание, что преобразование предварительной выборки дает преимущества каждый раз, когда есть возможность совмещать работу «производителя» с работой «потребителя»."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DHpUVqH1-jKi"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h7z_kzo--jKn"
      },
      "source": [
        "![опережающая выборка](https://www.tensorflow.org/guide/images/data_performance/prefetched.svg)\n",
        "\n",
        "На этот раз вы можете видеть, что во время этапа обучения для выборки 0 входной конвейер считывает данные для выборки 1 и так далее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "52QMKfaY-jKq"
      },
      "source": [
        "### Распараллеливание извлечения данных\n",
        "\n",
        "В реальных условиях входные данные могут храниться удаленно (например, GCS или HDFS). Конвейер набора данных, который хорошо работает при локальном чтении данных, может стать узким местом при вводе-выводе при удаленном чтении данных из-за следующих различий между локальным и удаленным хранилищем:\n",
        "\n",
        "- **Время до первого байта:** чтение первого байта файла из удаленного хранилища может занять на несколько порядков больше времени, чем из локального хранилища.\n",
        "- Пропускная способность чтения **:** хотя удаленное хранилище обычно предлагает большую совокупную пропускную способность, чтение одного файла может использовать только небольшую часть этой пропускной способности.\n",
        "\n",
        "Кроме того, после загрузки необработанных байтов в память может также потребоваться десериализация и / или дешифрование данных (например, [protobuf](https://developers.google.com/protocol-buffers/) ), что требует дополнительных вычислений. Эти издержки присутствуют независимо от того, хранятся ли данные локально или удаленно, но могут быть хуже в удаленном случае, если данные не были предварительно эффективно извлечены.\n",
        "\n",
        "To mitigate the impact of the various data extraction overheads, the `tf.data.Dataset.interleave` transformation can be used to parallelize the data loading step, interleaving the contents of other datasets (such as data file readers). The number of datasets to overlap can be specified by the `cycle_length` argument, while the level of parallelism can be specified by the `num_parallel_calls` argument. Similar to the `prefetch` transformation, the `interleave` transformation supports `tf.data.experimental.AUTOTUNE` which will delegate the decision about what level of parallelism to use to the `tf.data` runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gs8O8Vbu-jKu"
      },
      "source": [
        "#### Последовательное чередование\n",
        "\n",
        "The default arguments of the `tf.data.Dataset.interleave` transformation make it interleave single samples from two datasets sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fDH12GiK-jKw"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(ArtificialDataset)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "78CsSOnf-jK0"
      },
      "source": [
        "![Последовательное чередование](https://www.tensorflow.org/guide/images/data_performance/sequential_interleave.svg)\n",
        "\n",
        "Этот график позволяет продемонстрировать поведение преобразования `interleave` , выборочно выбирая выборки из двух доступных наборов данных. Тем не менее, никакого улучшения производительности здесь не происходит."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j3cqqmYl-jK2"
      },
      "source": [
        "#### Параллельное чередование\n",
        "\n",
        "Теперь используйте аргумент `num_parallel_calls` преобразования `interleave` . Это загружает несколько наборов данных параллельно, сокращая время ожидания открытия файлов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "a3FQcTPY-jK4"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(\n",
        "        ArtificialDataset,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RxRLPB6C-jLA"
      },
      "source": [
        "![Параллельное чередование](https://www.tensorflow.org/guide/images/data_performance/parallel_interleave.svg)\n",
        "\n",
        "На этот раз чтение двух наборов данных распараллелено, что сокращает общее время обработки данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5ZCLFWyv-jLB"
      },
      "source": [
        "### Распараллеливание преобразования данных\n",
        "\n",
        "При подготовке данных элементы ввода могут нуждаться в предварительной обработке. Для этого API `tf.data` предлагает преобразование `tf.data.Dataset.map` , которое применяет пользовательскую функцию к каждому элементу входного набора данных. Поскольку входные элементы не зависят друг от друга, предварительная обработка может быть распараллелена на нескольких ядрах ЦП. Чтобы сделать это возможным, подобно преобразованиям `prefetch` и `interleave` преобразование `map` предоставляет аргумент `num_parallel_calls` для указания уровня параллелизма.\n",
        "\n",
        "Choosing the best value for the `num_parallel_calls` argument depends on your hardware, characteristics of your training data (such as its size and shape), the cost of your map function, and what other processing is happening on the CPU at the same time. A simple heuristic is to use the number of available CPU cores. However, as for the `prefetch` and `interleave` transformation, the `map` transformation supports `tf.data.experimental.AUTOTUNE` which will delegate the decision about what level of parallelism to use to the `tf.data` runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GSkKetpx-jLD"
      },
      "outputs": [],
      "source": [
        "def mapped_function(s):\n",
        "    # Do some hard pre-processing\n",
        "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wiU7W_QC-jLI"
      },
      "source": [
        "#### Последовательное отображение\n",
        "\n",
        "Начните с использования преобразования `map` без параллелизма в качестве базового примера."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZSBvDpJG-jLL"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(mapped_function)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngwMTDb6-jLR"
      },
      "source": [
        "![Последовательное отображение](https://www.tensorflow.org/guide/images/data_performance/sequential_map.svg)\n",
        "\n",
        "Что касается [наивного подхода](#The-naive-approach) , то здесь время, затраченное на открытие, чтение, предварительную обработку (отображение) и этапы обучения, суммируется за одну итерацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U-10PE1D-jLU"
      },
      "source": [
        "#### Параллельное отображение\n",
        "\n",
        "Теперь используйте ту же функцию предварительной обработки, но примените ее параллельно на нескольких выборках."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F8AYLZbg-jLV"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(\n",
        "        mapped_function,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-MoJklzP-jLe"
      },
      "source": [
        "![Параллельное отображение](https://www.tensorflow.org/guide/images/data_performance/parallel_map.svg)\n",
        "\n",
        "Теперь на графике видно, что этапы предварительной обработки перекрываются, сокращая общее время одной итерации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZY1Q9kJO-jLh"
      },
      "source": [
        "### Кэширование\n",
        "\n",
        "Преобразование `tf.data.Dataset.cache` может кэшировать набор данных либо в памяти, либо в локальном хранилище. Это спасет некоторые операции (такие как открытие файла и чтение данных) от выполнения во время каждой эпохи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xieLApaI-jLi"
      },
      "outputs": [],
      "source": [
        "benchmark(\n",
        "    ArtificialDataset()\n",
        "    .map(  # Apply time consuming operations before cache\n",
        "        mapped_function\n",
        "    ).cache(\n",
        "    ),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KeMgW9XI-jLn"
      },
      "source": [
        "![Кэшированный набор данных](https://www.tensorflow.org/guide/images/data_performance/cached_dataset.svg)\n",
        "\n",
        "Когда вы кешируете набор данных, преобразования перед `cache` (например, открытие файла и чтение данных) выполняются только в течение первой эпохи. Следующие эпохи будут повторно использовать данные, кэшированные с помощью преобразования `cache` .\n",
        "\n",
        "Если пользовательская функция, переданная в преобразование `map` является дорогостоящей, применяйте преобразование `cache` после преобразования `map` если полученный набор данных все еще может помещаться в память или локальное хранилище. Если пользовательская функция увеличивает пространство, необходимое для хранения набора данных, за пределами емкости кеша, либо примените ее после преобразования `cache` либо рассмотрите возможность предварительной обработки данных перед тренировкой, чтобы уменьшить использование ресурсов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i3NtGI3r-jLp"
      },
      "source": [
        "### Векторизация картирования\n",
        "\n",
        "Вызов пользовательской функции, переданной в преобразование `map` , связан с планированием и выполнением пользовательской функции. Мы рекомендуем векторизовать определяемую пользователем функцию (то есть, чтобы она работала с партией входов одновременно) и применить `batch` преобразование *перед* преобразованием `map` .\n",
        "\n",
        "Чтобы проиллюстрировать эту хорошую практику, ваш искусственный набор данных не подходит. Задержка планирования составляет около 10 микросекунд (10e-6 секунд), что намного меньше, чем десятки миллисекунд, используемых в `ArtificialDataset` , и, следовательно, ее влияние трудно увидеть.\n",
        "\n",
        "Для этого примера используйте базовую функцию `tf.data.Dataset.range` и упростите обучающий цикл до его самой простой формы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xqtiYPmb-jLt"
      },
      "outputs": [],
      "source": [
        "fast_dataset = tf.data.Dataset.range(10000)\n",
        "\n",
        "def fast_benchmark(dataset, num_epochs=2):\n",
        "    start_time = time.perf_counter()\n",
        "    for _ in tf.data.Dataset.range(num_epochs):\n",
        "        for _ in dataset:\n",
        "            pass\n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
        "    \n",
        "def increment(x):\n",
        "    return x+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fj2gmsMT-jL5"
      },
      "source": [
        "#### Скалярное отображение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Imn3SslJ-jMA"
      },
      "outputs": [],
      "source": [
        "fast_benchmark(\n",
        "    fast_dataset\n",
        "    # Apply function one item at a time\n",
        "    .map(increment)\n",
        "    # Batch\n",
        "    .batch(256)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BWUNbPqv-jMF"
      },
      "source": [
        "![Скалярная карта](https://www.tensorflow.org/guide/images/data_performance/scalar_map.svg)\n",
        "\n",
        "График выше иллюстрирует, что происходит (с меньшим количеством образцов). Вы можете видеть, что отображенная функция применяется для каждого образца. Хотя эта функция очень быстрая, она имеет некоторые накладные расходы, которые влияют на производительность по времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tDVSM0A--jMG"
      },
      "source": [
        "#### Векторизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nAw1mDLw-jMI"
      },
      "outputs": [],
      "source": [
        "fast_benchmark(\n",
        "    fast_dataset\n",
        "    .batch(256)\n",
        "    # Apply function on a batch of items\n",
        "    # The tf.Tensor.__add__ method already handle batches\n",
        "    .map(increment)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DbMteMY9-jMO",
        "scrolled": false
      },
      "source": [
        "![Векторизованная карта](https://www.tensorflow.org/guide/images/data_performance/vectorized_map.svg)\n",
        "\n",
        "На этот раз сопоставленная функция вызывается один раз и применяется к партии выборки. Хотя выполнение функции может занять больше времени, накладные расходы появляются только один раз, что повышает общую производительность по времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hfueG0Wj-jMR"
      },
      "source": [
        "### Уменьшение памяти\n",
        "\n",
        "Ряд преобразований, включая `interleave` , `prefetch` и `shuffle` , поддерживают внутренний буфер элементов. Если пользовательская функция, переданная в преобразование `map` изменяет размер элементов, то порядок преобразования карты и преобразования, которые буферизуют элементы, влияют на использование памяти. В общем, мы рекомендуем выбирать порядок, который приводит к уменьшению объема памяти, если для производительности не требуется другой порядок.\n",
        "\n",
        "#### Кэширование частичных вычислений\n",
        "\n",
        "Рекомендуется кэшировать набор данных после преобразования `map` за исключением случаев, когда это преобразование делает данные слишком большими для размещения в памяти. Компромисс может быть достигнут, если ваша отображенная функция может быть разделена на две части: одну, занимающую много времени, и часть, занимающую память. В этом случае вы можете связать свои преобразования, как показано ниже:\n",
        "\n",
        "```python\n",
        "dataset.map(time_consuming_mapping).cache().map(memory_consuming_mapping)\n",
        "```\n",
        "\n",
        "Таким образом, трудоемкая часть выполняется только в течение первой эпохи, и вы избегаете использовать слишком много места в кеше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MYOHG69M-jMT"
      },
      "source": [
        "## Краткое изложение практики\n",
        "\n",
        "Вот краткое изложение лучших практик для проектирования высокопроизводительных входных конвейеров TensorFlow:\n",
        "\n",
        "- [Используйте преобразование `prefetch`](#Pipelining) чтобы перекрыть работу производителя и потребителя.\n",
        "- [Распараллелить преобразование чтения данных,](#Parallelizing-data-extraction) используя преобразование `interleave` .\n",
        "- [Распараллелить преобразование `map`](#Parallelizing-data-transformation) , установив аргумент `num_parallel_calls` .\n",
        "- [Используйте преобразование `cache`](#Caching) для кэширования данных в памяти в течение первой эпохи\n",
        "- [Векторизация пользовательских функций,](#Map-and-batch) переданных в преобразование `map`\n",
        "- [Сократите использование памяти](#Reducing-memory-footprint) при применении преобразований `interleave` , `prefetch` и `shuffle` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mP_EMFsQ-jMU"
      },
      "source": [
        "## Воспроизведение фигур\n",
        "\n",
        "Примечание. В остальной части этого блокнота рассказывается о том, как воспроизвести приведенные выше рисунки. Не стесняйтесь поиграть с этим кодом, но его понимание не является важной частью этого руководства.\n",
        "\n",
        "To go deeper in the `tf.data.Dataset` API understanding, you can play with your own pipelines. Below is the code used to plot the images from this guide. It can be a good starting point, showing some workarounds for common difficulties such as:\n",
        "\n",
        "- Воспроизводимость времени исполнения;\n",
        "- Сопоставленные функции нетерпеливого исполнения;\n",
        "- преобразование `interleave`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7M_jFLer-jMV"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z3pjnxtK-jMa"
      },
      "source": [
        "### Набор данных\n",
        "\n",
        "По аналогии с `ArtificialDataset` вы можете создать набор данных, возвращающий время, затраченное на каждый шаг."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OgGl4U7t-jMc"
      },
      "outputs": [],
      "source": [
        "class TimeMeasuredDataset(tf.data.Dataset):\n",
        "    # OUTPUT: (steps, timings, counters)\n",
        "    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)\n",
        "    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))\n",
        "    \n",
        "    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated\n",
        "    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset\n",
        "    \n",
        "    def _generator(instance_idx, num_samples):\n",
        "        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n",
        "        \n",
        "        # Opening the file\n",
        "        open_enter = time.perf_counter()\n",
        "        time.sleep(0.03)\n",
        "        open_elapsed = time.perf_counter() - open_enter\n",
        "        \n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            read_enter = time.perf_counter()\n",
        "            time.sleep(0.015)\n",
        "            read_elapsed = time.perf_counter() - read_enter\n",
        "            \n",
        "            yield (\n",
        "                [(\"Open\",), (\"Read\",)],\n",
        "                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n",
        "                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]\n",
        "            )\n",
        "            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered\n",
        "            \n",
        "    \n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls._generator,\n",
        "            output_types=cls.OUTPUT_TYPES,\n",
        "            output_shapes=cls.OUTPUT_SHAPES,\n",
        "            args=(next(cls._INSTANCES_COUNTER), num_samples)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YQqDP4jk-jMj"
      },
      "source": [
        "Этот набор данных предоставляет образцы формы `[[2, 1], [2, 2], [2, 3]]` и типа `[tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32]` . Каждый образец:\n",
        "\n",
        "```\n",
        "(   [(\"Open\"), (\"Read\")],   [(t0, d), (t0, d)],   [(i, e, -1), (i, e, s)] )\n",
        "```\n",
        "\n",
        "Куда:\n",
        "\n",
        "- `Open` и `Read` - идентификаторы шагов\n",
        "- `t0` - отметка времени, когда начался соответствующий шаг\n",
        "- `d` - время, проведенное на соответствующем шаге\n",
        "- `i` индекс экземпляра\n",
        "- `e` - индекс эпохи (количество повторений набора данных)\n",
        "- `s` - индекс выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IQK913bB-jMm"
      },
      "source": [
        "### Цикл итерации\n",
        "\n",
        "Сделайте цикл итерации немного сложнее, чтобы агрегировать все тайминги. Это будет работать только с наборами данных, генерирующими образцы, как описано выше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zAy-K_Cq-jMn"
      },
      "outputs": [],
      "source": [
        "def timelined_benchmark(dataset, num_epochs=2):\n",
        "    # Initialize accumulators\n",
        "    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n",
        "    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n",
        "    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n",
        "    \n",
        "    start_time = time.perf_counter()\n",
        "    for epoch_num in range(num_epochs):\n",
        "        epoch_enter = time.perf_counter()\n",
        "        for (steps, times, values) in dataset:\n",
        "            # Record dataset preparation informations\n",
        "            steps_acc = tf.concat((steps_acc, steps), axis=0)\n",
        "            times_acc = tf.concat((times_acc, times), axis=0)\n",
        "            values_acc = tf.concat((values_acc, values), axis=0)\n",
        "            \n",
        "            # Simulate training time\n",
        "            train_enter = time.perf_counter()\n",
        "            time.sleep(0.01)\n",
        "            train_elapsed = time.perf_counter() - train_enter\n",
        "            \n",
        "            # Record training informations\n",
        "            steps_acc = tf.concat((steps_acc, [[\"Train\"]]), axis=0)\n",
        "            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)\n",
        "            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)\n",
        "        \n",
        "        epoch_elapsed = time.perf_counter() - epoch_enter\n",
        "        # Record epoch informations\n",
        "        steps_acc = tf.concat((steps_acc, [[\"Epoch\"]]), axis=0)\n",
        "        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)\n",
        "        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)\n",
        "        time.sleep(0.001)\n",
        "    \n",
        "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
        "    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jw_WSQC8-jMs"
      },
      "source": [
        "### Метод построения\n",
        "\n",
        "Наконец, определите функцию, способную построить временную шкалу с учетом значений, возвращаемых функцией `timelined_benchmark` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1j73RxiP-jMw"
      },
      "outputs": [],
      "source": [
        "def draw_timeline(timeline, title, width=0.5, annotate=False, save=False):\n",
        "    # Remove invalid entries (negative times, or empty steps) from the timelines\n",
        "    invalid_mask = np.logical_and(timeline['times'] > 0, timeline['steps'] != b'')[:,0]\n",
        "    steps = timeline['steps'][invalid_mask].numpy()\n",
        "    times = timeline['times'][invalid_mask].numpy()\n",
        "    values = timeline['values'][invalid_mask].numpy()\n",
        "    \n",
        "    # Get a set of different steps, ordered by the first time they are encountered\n",
        "    step_ids, indices = np.stack(np.unique(steps, return_index=True))\n",
        "    step_ids = step_ids[np.argsort(indices)]\n",
        "\n",
        "    # Shift the starting time to 0 and compute the maximal time value\n",
        "    min_time = times[:,0].min()\n",
        "    times[:,0] = (times[:,0] - min_time)\n",
        "    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)\n",
        "    \n",
        "    cmap = mpl.cm.get_cmap(\"plasma\")\n",
        "    plt.close()\n",
        "    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={'hspace': 0})\n",
        "    fig.suptitle(title)\n",
        "    fig.set_size_inches(17.0, len(step_ids))\n",
        "    plt.xlim(-0.01, end)\n",
        "    \n",
        "    for i, step in enumerate(step_ids):\n",
        "        step_name = step.decode()\n",
        "        ax = axs[i]\n",
        "        ax.set_ylabel(step_name)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xlabel(\"time (s)\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.grid(which=\"both\", axis=\"x\", color=\"k\", linestyle=\":\")\n",
        "        \n",
        "        # Get timings and annotation for the given step\n",
        "        entries_mask = np.squeeze(steps==step)\n",
        "        serie = np.unique(times[entries_mask], axis=0)\n",
        "        annotations = values[entries_mask]\n",
        "        \n",
        "        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)\n",
        "        if annotate:\n",
        "            for j, (start, width) in enumerate(serie):\n",
        "                annotation = \"\\n\".join([f\"{l}: {v}\" for l,v in zip((\"i\", \"e\", \"s\"), annotations[j])])\n",
        "                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,\n",
        "                        horizontalalignment='left', verticalalignment='center')\n",
        "    if save:\n",
        "        plt.savefig(title.lower().translate(str.maketrans(\" \", \"_\")) + \".svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xto6GNdO-jM1"
      },
      "source": [
        "### Используйте обертки для сопоставленной функции\n",
        "\n",
        "Чтобы запустить сопоставленную функцию в активном контексте, вы должны обернуть их внутри вызова `tf.py_function` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "39v7JD4L-jM2"
      },
      "outputs": [],
      "source": [
        "def map_decorator(func):\n",
        "    def wrapper(steps, times, values):\n",
        "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
        "        return tf.py_function(\n",
        "            func,\n",
        "            inp=(steps, times, values),\n",
        "            Tout=(steps.dtype, times.dtype, values.dtype)\n",
        "        )\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7eJRCinb-jM5"
      },
      "source": [
        "### Сравнение трубопроводов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YwX4ndHE-jM6"
      },
      "outputs": [],
      "source": [
        "_batch_map_num_items = 50\n",
        "\n",
        "def dataset_generator_fun(*args):\n",
        "    return TimeMeasuredDataset(num_samples=_batch_map_num_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EwxJT2aR-jNA"
      },
      "source": [
        "#### наивный"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wLKgurx_-jNC"
      },
      "outputs": [],
      "source": [
        "@map_decorator\n",
        "def naive_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001)  # Time consuming step\n",
        "    time.sleep(0.0001)  # Memory consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, [[\"Map\"]]), axis=0),\n",
        "        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\n",
        "        tf.concat((values, [values[-1]]), axis=0)\n",
        "    )\n",
        "\n",
        "naive_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .flat_map(dataset_generator_fun)\n",
        "    .map(naive_map)\n",
        "    .batch(_batch_map_num_items, drop_remainder=True)\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EJqUMDsO-jNG"
      },
      "source": [
        "### оптимизированный"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HYHcwabr-jNH"
      },
      "outputs": [],
      "source": [
        "@map_decorator\n",
        "def time_consuming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.001 * values.shape[0])  # Time consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"1st map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "@map_decorator\n",
        "def memory_consuming_map(steps, times, values):\n",
        "    map_enter = time.perf_counter()\n",
        "    time.sleep(0.0001 * values.shape[0])  # Memory consuming step\n",
        "    map_elapsed = time.perf_counter() - map_enter\n",
        "\n",
        "    # Use tf.tile to handle batch dimension\n",
        "    return (\n",
        "        tf.concat((steps, tf.tile([[[\"2nd map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
        "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
        "    )\n",
        "\n",
        "\n",
        "optimized_timeline = timelined_benchmark(\n",
        "    tf.data.Dataset.range(2)\n",
        "    .interleave(  # Parallelize data reading\n",
        "        dataset_generator_fun,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .batch(  # Vectorize your mapped function\n",
        "        _batch_map_num_items,\n",
        "        drop_remainder=True)\n",
        "    .map(  # Parallelize map transformation\n",
        "        time_consuming_map,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .cache()  # Cache data\n",
        "    .map(  # Reduce memory usage\n",
        "        memory_consuming_map,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .prefetch(  # Overlap producer and consumer works\n",
        "        tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .unbatch(),\n",
        "    5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "b_CSUbxL-jNK"
      },
      "outputs": [],
      "source": [
        "draw_timeline(naive_timeline, \"Naive\", 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DoovY7qr-jNR"
      },
      "outputs": [],
      "source": [
        "draw_timeline(optimized_timeline, \"Optimized\", 15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_performance.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
