{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fEwwyiWMlncS"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "lT4CrDemeqzN"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w5BqikBFR8Jb"
      },
      "source": [
        "# Rédaction de vos propres rappels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYNefYV3toRo"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/custom_callback\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> Voir sur TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/keras-team/keras-io/blob/master/tf/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"> Exécuter dans Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/keras-team/keras-io/blob/master/guides/writing_your_own_callbacks.py\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Afficher la source sur GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/keras-io/tf/custom_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\"> Télécharger le cahier</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M80XSuTIvJld"
      },
      "source": [
        "## introduction\n",
        "\n",
        "Un rappel est un outil puissant pour personnaliser le comportement d'un modèle Keras pendant l'entraînement, l'évaluation ou l'inférence. Les exemples incluent `tf.keras.callbacks.TensorBoard` pour visualiser la progression et les résultats de l'entraînement avec TensorBoard, ou `tf.keras.callbacks.ModelCheckpoint` pour enregistrer périodiquement votre modèle pendant l'entraînement.\n",
        "\n",
        "Dans ce guide, vous apprendrez ce qu'est un rappel Keras, ce qu'il peut faire et comment vous pouvez créer le vôtre. Nous proposons quelques démos d'applications de rappel simples pour vous aider à démarrer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6Tx5DcPg1o6"
      },
      "source": [
        "## Installer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "UxOi7EEE6Q9Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DjgZ3jSko2kU"
      },
      "source": [
        "## Présentation des rappels Keras\n",
        "\n",
        "All callbacks subclass the `keras.callbacks.Callback` class, and override a set of methods called at various stages of training, testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training.\n",
        "\n",
        "Vous pouvez transmettre une liste de rappels (en tant que `callbacks` argument de mot-clé) aux méthodes de modèle suivantes:\n",
        "\n",
        "- `keras.Model.fit()`\n",
        "- `keras.Model.evaluate()`\n",
        "- `keras.Model.predict()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VpW1Q0YjwH4s"
      },
      "source": [
        "## Un aperçu des méthodes de rappel\n",
        "\n",
        "### Méthodes globales\n",
        "\n",
        "#### `on_(train|test|predict)_begin(self, logs=None)`\n",
        "\n",
        "Appelé au début de l' `fit` / `evaluate` / `predict` .\n",
        "\n",
        "#### `on_(train|test|predict)_end(self, logs=None)`\n",
        "\n",
        "Appelé à la fin de l' `fit` / `evaluate` / `predict` .\n",
        "\n",
        "### Méthodes au niveau du lot pour la formation / le test / la prévision\n",
        "\n",
        "#### `on_(train|test|predict)_batch_begin(self, batch, logs=None)`\n",
        "\n",
        "Appelé juste avant de traiter un lot pendant la formation / les tests / les prévisions.\n",
        "\n",
        "#### `on_(train|test|predict)_batch_end(self, batch, logs=None)`\n",
        "\n",
        "Appelé à la fin de la formation / test / prédiction d'un lot. Dans cette méthode, `logs` est un dict contenant les résultats des métriques.\n",
        "\n",
        "### Méthodes au niveau de l'époque (formation uniquement)\n",
        "\n",
        "#### `on_epoch_begin(self, epoch, logs=None)`\n",
        "\n",
        "Appelé au début d'une époque pendant l'entraînement.\n",
        "\n",
        "#### `on_epoch_end(self, epoch, logs=None)`\n",
        "\n",
        "Appelé à la fin d'une époque pendant l'entraînement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wt9nVKBw2Zbd"
      },
      "source": [
        "## Un exemple basique\n",
        "\n",
        "Prenons un exemple concret. Pour commencer, importons tensorflow et définissons un modèle Keras séquentiel simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "pE2CcBRVisfl"
      },
      "outputs": [],
      "source": [
        "# Define the Keras model to add callbacks to\n",
        "def get_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(1, input_dim=784))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.RMSprop(learning_rate=0.1),\n",
        "        loss=\"mean_squared_error\",\n",
        "        metrics=[\"mean_absolute_error\"],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "csY3ImU6n4AE"
      },
      "source": [
        "Ensuite, chargez les données MNIST pour l'entraînement et les tests à partir de l'API des ensembles de données Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "m39zXsmb6brk"
      },
      "outputs": [],
      "source": [
        "# Load example MNIST data and pre-process it\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "\n",
        "# Limit the data to 1000 samples\n",
        "x_train = x_train[:1000]\n",
        "y_train = y_train[:1000]\n",
        "x_test = x_test[:1000]\n",
        "y_test = y_test[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ah1Hsy79P0tI"
      },
      "source": [
        "Maintenant, définissez un simple rappel personnalisé qui enregistre:\n",
        "\n",
        "- Quand `fit` / `evaluate` / `predict` début et la fin\n",
        "- Quand chaque époque commence et se termine\n",
        "- Quand chaque lot d'entraînement commence et se termine\n",
        "- Quand chaque lot d'évaluation (test) commence et se termine\n",
        "- Quand chaque lot d'inférence (prédiction) commence et se termine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "PVzRdrXuQYo7"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Starting training; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Stop training; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start testing; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Stop testing; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start predicting; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Stop predicting; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zaOKC7dpK7ng"
      },
      "source": [
        "Essayons-le:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "IiFWfxsNkypE"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=1,\n",
        "    verbose=0,\n",
        "    validation_split=0.5,\n",
        "    callbacks=[CustomCallback()],\n",
        ")\n",
        "\n",
        "res = model.evaluate(\n",
        "    x_test, y_test, batch_size=128, verbose=0, callbacks=[CustomCallback()]\n",
        ")\n",
        "\n",
        "res = model.predict(x_test, batch_size=128, callbacks=[CustomCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y9oQfhHERRsm"
      },
      "source": [
        "### Utilisation des `logs` dict\n",
        "\n",
        "Le `logs` dict contient la valeur de la perte et toutes les métriques à la fin d'un lot ou d'une époque. L'exemple comprend la perte et l'erreur absolue moyenne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "dVErv1llBq0l"
      },
      "outputs": [],
      "source": [
        "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(\"For batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        print(\"For batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\n",
        "            \"The average loss for epoch {} is {:7.2f} \"\n",
        "            \"and mean absolute error is {:7.2f}.\".format(\n",
        "                epoch, logs[\"loss\"], logs[\"mean_absolute_error\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    verbose=0,\n",
        "    callbacks=[LossAndErrorPrintingCallback()],\n",
        ")\n",
        "\n",
        "res = model.evaluate(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    batch_size=128,\n",
        "    verbose=0,\n",
        "    callbacks=[LossAndErrorPrintingCallback()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AC03ymKbxZNq"
      },
      "source": [
        "## Utilisation de l'attribut `self.model`\n",
        "\n",
        "En plus de recevoir des informations de journal lorsque l'une de leurs méthodes est appelée, les callbacks ont accès au modèle associé à la ronde actuelle de formation / évaluation / inférence: `self.model` .\n",
        "\n",
        "Voici quelques-unes des choses que vous pouvez faire avec `self.model` dans un rappel:\n",
        "\n",
        "- Définissez `self.model.stop_training = True` pour interrompre immédiatement l'entraînement.\n",
        "- Mutation des hyperparamètres de l'optimiseur (disponibles sous le nom de `self.model.optimizer` ), tels que `self.model.optimizer.learning_rate` .\n",
        "- Enregistrez le modèle à intervalles réguliers.\n",
        "- Enregistrez la sortie de `model.predict()` sur quelques échantillons de test à la fin de chaque époque, à utiliser comme contrôle de cohérence pendant la formation.\n",
        "- Extrayez des visualisations des caractéristiques intermédiaires à la fin de chaque époque, pour surveiller ce que le modèle apprend au fil du temps.\n",
        "- etc.\n",
        "\n",
        "Voyons cela en action dans quelques exemples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H2GuBD9Pl7Hg"
      },
      "source": [
        "## Exemples d'applications de rappel Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kR5WkzikUzX8"
      },
      "source": [
        "### Arrêt précoce avec une perte minimale\n",
        "\n",
        "Ce premier exemple montre la création d'un `Callback` qui arrête l'entraînement lorsque le minimum de perte a été atteint, en définissant l'attribut `self.model.stop_training` (booléen). En option, vous pouvez fournir un argument `patience` pour spécifier combien d'époques nous devons attendre avant de s'arrêter après avoir atteint un minimum local.\n",
        "\n",
        "`tf.keras.callbacks.EarlyStopping` fournit une implémentation plus complète et plus générale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "lbTowW8Tbk8Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
        "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
        "\n",
        "  Arguments:\n",
        "      patience: Number of epochs to wait after min has been hit. After this\n",
        "      number of no improvement, training stops.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, patience=0):\n",
        "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
        "        self.patience = patience\n",
        "        # best_weights to store the weights at which the minimum loss occurs.\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # The number of epoch it has waited when loss is no longer minimum.\n",
        "        self.wait = 0\n",
        "        # The epoch the training stops at.\n",
        "        self.stopped_epoch = 0\n",
        "        # Initialize the best as infinity.\n",
        "        self.best = np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(\"loss\")\n",
        "        if np.less(current, self.best):\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            # Record the best weights if current results is better (less).\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    steps_per_epoch=5,\n",
        "    epochs=30,\n",
        "    verbose=0,\n",
        "    callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TU1xXEs9VES9"
      },
      "source": [
        "### Planification du taux d'apprentissage\n",
        "\n",
        "Dans cet exemple, nous montrons comment un rappel personnalisé peut être utilisé pour modifier dynamiquement le taux d'apprentissage de l'optimiseur au cours de la formation.\n",
        "\n",
        "Voir `callbacks.LearningRateScheduler` pour une implémentation plus générale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "aOhw3UB85Vao"
      },
      "outputs": [],
      "source": [
        "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
        "\n",
        "  Arguments:\n",
        "      schedule: a function that takes an epoch index\n",
        "          (integer, indexed from 0) and current learning rate\n",
        "          as inputs and returns a new learning rate as output (float).\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, schedule):\n",
        "        super(CustomLearningRateScheduler, self).__init__()\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, \"lr\"):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        # Get the current learning rate from model's optimizer.\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "        # Call schedule function to get the scheduled learning rate.\n",
        "        scheduled_lr = self.schedule(epoch, lr)\n",
        "        # Set the value back to the optimizer before this epoch starts\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
        "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
        "\n",
        "\n",
        "LR_SCHEDULE = [\n",
        "    # (epoch to start, learning rate) tuples\n",
        "    (3, 0.05),\n",
        "    (6, 0.01),\n",
        "    (9, 0.005),\n",
        "    (12, 0.001),\n",
        "]\n",
        "\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
        "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
        "        return lr\n",
        "    for i in range(len(LR_SCHEDULE)):\n",
        "        if epoch == LR_SCHEDULE[i][0]:\n",
        "            return LR_SCHEDULE[i][1]\n",
        "    return lr\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    steps_per_epoch=5,\n",
        "    epochs=15,\n",
        "    verbose=0,\n",
        "    callbacks=[\n",
        "        LossAndErrorPrintingCallback(),\n",
        "        CustomLearningRateScheduler(lr_schedule),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fwr7dO76pJr9"
      },
      "source": [
        "### Callbacks Keras intégrés\n",
        "\n",
        "Be sure to check out the existing Keras callbacks by reading the [API docs](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/). Applications include logging to CSV, saving the model, visualizing metrics in TensorBoard, and a lot more!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "custom_callback.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
